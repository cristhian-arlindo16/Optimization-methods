import matplotlib
# Establecer el backend de matplotlib a 'Agg' para evitar el uso de Tkinter
matplotlib.use('Agg')
import matplotlib.pyplot as plt

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, LinearRegression
from sklearn.metrics import mean_squared_error

# Cargar el archivo CSV
file_path = "SociedadesBIC_01_2023.csv"  # Aseg√∫rate de que la ruta est√© correcta
df = pd.read_csv(file_path, encoding="latin1")

# Convertir variables categ√≥ricas en num√©ricas
df_encoded = pd.get_dummies(df, drop_first=True)

# Seleccionar solo columnas num√©ricas
df_numeric = df_encoded.select_dtypes(include=[np.number])

# Eliminar o imputar los valores faltantes
df_numeric = df_numeric.dropna()  # Eliminar filas con NaN

# Verificar que hay suficientes columnas num√©ricas
if df_numeric.shape[1] < 2:
    print("\n‚ö†Ô∏è No hay suficientes columnas num√©ricas para aplicar Regresi√≥n Ridge.")
else:
    # Seleccionar variables predictoras (X) y la variable objetivo (y)
    X = df_numeric.drop(columns=["PERIODO_INFORME"])  # Cambia "PERIODO_INFORME" si quieres predecir otra columna
    y = df_numeric["PERIODO_INFORME"]

    # Verificar que X no est√© vac√≠o
    if X.shape[1] < 2:
        raise ValueError("‚ö†Ô∏è No hay suficientes columnas num√©ricas para entrenar el modelo.")

    # Dividir en entrenamiento y prueba
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Escalar caracter√≠sticas
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Modelo de Regresi√≥n Lineal
    lr = LinearRegression()
    lr.fit(X_train_scaled, y_train)
    y_pred_lr = lr.predict(X_test_scaled)
    mse_lr = mean_squared_error(y_test, y_pred_lr)

    # Modelo Ridge con lambda=1.0
    ridge = Ridge(alpha=1.0)
    ridge.fit(X_train_scaled, y_train)
    y_pred_ridge = ridge.predict(X_test_scaled)
    mse_ridge = mean_squared_error(y_test, y_pred_ridge)

    # Comparaci√≥n de errores
    print("\nüìä Comparaci√≥n de Modelos:")
    print(f"Regresi√≥n Lineal MSE: {mse_lr:.2f}")
    print(f"Ridge Regression (Œª=1.0) MSE: {mse_ridge:.2f}")

    # Visualizaci√≥n de predicciones y guardado del gr√°fico
    plt.figure(figsize=(8, 5))

    # Gr√°fica de Regresi√≥n Lineal
    plt.scatter(y_test, y_pred_lr, label="Regresi√≥n Lineal", color="blue", alpha=0.7)

    # Gr√°fica de Ridge Regression
    plt.scatter(y_test, y_pred_ridge, label="Ridge Regression", color="orange", alpha=0.7)

    # L√≠nea ideal donde las predicciones son iguales a los valores reales
    plt.plot(y_test, y_test, color="black", linestyle="dashed", label="Ideal")

    # Etiquetas y t√≠tulo
    plt.xlabel("Valores Reales")
    plt.ylabel("Predicciones")
    plt.title("Comparaci√≥n de Predicciones: Regresi√≥n Lineal vs Ridge")

    # Mostrar la leyenda
    plt.legend()

    # Guardar el gr√°fico como archivo PNG
    plt.savefig("comparacion_modelos.png")

    # Tambi√©n puedes mostrar el gr√°fico sin Tkinter si quieres ver el archivo generado
    # plt.show()  # Comentado ya que estamos usando un backend sin interfaz gr√°fica

    print("\n‚úÖ Gr√°fico guardado como 'comparacion_modelos.png'.")
